\documentclass[12pt]{article}
\usepackage[hidelinks]{hyperref}
\usepackage[square,sort,comma,numbers]{natbib}
\usepackage{graphicx}
\title{Literature Survey}
\author{
    Andrew Mason\\
    \texttt{ajm188@case.edu}
    \and
    Jon Pfeil\\
    \texttt{jwp69@case.edu}
}
\date{December 8, 2014}
\begin{document}
\maketitle
\tableofcontents
\pagebreak

\section{Introduction and Software Verification}
Knowing that a software system fulfills a set of requirements correctly is an
important concern in industry, especially for mission-critical software
systems, such as the avionics software in an airplane, or the software in
medical devices. Approaches to software verification can be separated into
categories, dynamic approaches and static approaches.
\\

\noindent Dynamic approaches to software verification include unit testing,
integration and system testing, and acceptance testing. While these methods 
can identify bugs in the software and help improve software quality, alone they
cannot confirm that the system is bug free and that the system fulfills all of
its requirements. A requirement may not be excerised by the tests, and there
may be a bug that occurs only on a particular input which the test suite does
not include.
\\

\noindent We prefer instead the static methods of software verification, known
also as program analysis or formal verification. These techniques aim to
provide a formal proof that a system satisfies a specified property. Numerous
approaches to formal verification exist, and we briefly highlight a few of
them below.
\\

\noindent Model-based certification aims to provide formal proofs that an
abstract model, such as a formal computational model, representing the software
system has a particular property\cite{FormalSoftwareVerification}. In this
approach, a verifier uses a model-checking tool to explore the state space of
the program, searching for error states, states where a certain property of the
system does not hold. One issue with this approach is that the state space for
even trivial programs can grow quite large, but predicate abstraction can be 
used to systematically reduce the state space\cite{FormalSoftwareVerification}.
\\

\noindent Deductive software proving, also referred to as program proving, aims
to express the correctness of a program as a set of mathematical statements,
which are then discharged using a theorem prover
\cite{DeductiveSoftwareVerification}. To do this, a formal specification
language must be defined and integrated with the desired programming language.
Filli√¢tre claims that the best method for achieving this is to tighten a
specification language to a programming language within a dedicated program
logic, which mixes programs and logical statements, infusing program
contstructs with logical ones in a single language
\cite{DeductiveSoftwareVerification}.

\section{Specification Mining}
Formal software verification has the potential to replace testing as the
standard method of verifying program correctness. However, formal program
verifiers are limited in that they can only check specified properties.
Additionally, authors Lo and Khoo claim that the difficulty in formulating a
set of formal properties has contributed to the lack of widespread adoption in
industry\cite{Lo_softwarespecification}. To solve this issue, the technique of
specification mining aims to discover non-trivial properties or specifications
in a software system to later be used by a program verifier.
\\

\noindent Several approaches to specification mining are described in the
literature, the first of which is a machine learning approach outlined by
Ammons et al. Their mining approach is based on program execution traces rather
than static analysis of source code. Ammons et al argue that this approach is
superior since the traces will only contain the feasible paths of execution.
Additionally, basing the mining on program traces ensure that only correct
execution paths are mined, thus preventing buggy paths from polluting the
results of the mining\cite{Ammons:2002:MS:503272.503275}. Their miner extracts
abstract scenarios from traces annotated with information about flow
dependence, which are small sets of independent interactions. These scenarios
are then fed into an automaton learner to learn the specifications. Ammons et
al give two reasons for this approach. First, the scenarios are much smaller
than the original traces, so the automaton learner learns the specifications
much faster. Second, the sizes of the scenarios are bounded, which they argue
make the specification mining tractable. The workflow of the miner looks like
\cite{Ammons:2002:MS:503272.503275}:\\
\includegraphics{machine_learning_miner_workflow.png}
\\

\noindent Lo and Khoo expand on the work of \cite{Ammons:2002:MS:503272.503275}
by describing their work in automaton-based specification mining, as well as
their work in mining Linear Temporal Logic (LTL) expressions and Live Sequence
Charts (LSC), which are alternate formalisms for representing specifications
\cite{Lo_softwarespecification}. Their approach also relies on execution traces
of the program. Lo and Khoo improve on \cite{Ammons:2002:MS:503272.503275} by
using a data mining approach that attempts to improve the quality of results,
since Ammons et al rely on the notion that traces give strong hints about
program rules, but do not really address the possibility that these traces may
contain errors. To this end, Lo and Khoo add an accuracy metric to measure the
performance of an automaton-based miner, which is measured by the notion of
recall and precision. They define recall and precision as "the proportion of
sentences in $S_{inf}$ that is accepted by $S_{orig}$ and the proportion of
sentences in $S_{orig}$ that is accepted by $S_{inf}$ where $S_{orig}$ is the
original specification and $S_{inf}$ is the inferred specification
\cite{Lo_softwarespecification}." Next, the authors devise a framework they
call SMArTIC that splits the specification mining task into four pipelined
components. They claim that this improves the quality of the mining because it
identifies and filters out erroneous traces early in the mining, and "the
over-generalization that occurs at the learning stage can be mitigated by
localization of the learning process to groups of related ... traces
\cite{Lo_softwarespecification}."
\\

\noindent Lo and Khoo also discuss their work in LTL specification mining,
which is one of the most commonly-accepted formalisms by standard verifiers.
LTL expressions break automata-based specifications (which are global and
often complex) into smaller pieces which express what the authors call
strongly observed behavior or rules. To identify these rules, Lo and Khoo
introduce the notions of support, which is the number of traces exhibiting the
premise of the rule, and confidence, which is the likelihood of the premise of
the rule to be followed by its consequence\cite{Lo_softwarespecification}.
They employ a search space pruning strategy to mine these rules from the
execution traces.

\section{Limiting False Positives}
Le Goues and Weimer\cite{Goues:2009:SMF:1532891.1532925} claim that
specification inference techniques suffer from 90-99\% false positive rates,
and thus require a heavy burden of manual inspection, making these techniques
impractical for most software projects. By defining the notion of code
trustworthiness, they are able to achieve false positive rates of only 5\%.
Their approach statically estimates the trustworthiness of each code fragment
and then weights the contribution of each trace by its trustworthiness, which
is determined by the trustworthiness of the fragments visited in the trace, in
the actual specification mining\cite{Goues:2009:SMF:1532891.1532925}. The code
trustworthiness is based on the notion that some code is more likely to be
correct than others. Le Goues and Weimer estimate this likelihood by using the
results of many studies in software engineering. For example, studies have
shown that code that is modified more frequently is more likely to contain
defects, so the approach looks at information obtained from the version control
system to determine the rate of what the authors call code churn
\cite{Goues:2009:SMF:1532891.1532925}.
\section{Code Clones}
\section{gSpan}
\subsection{Subgraph Isomorphism}
\subsection{Frequent Subgraph Mining}
\pagebreak
\bibliographystyle{acm}
\bibliography{lit_survey}
\end{document}
