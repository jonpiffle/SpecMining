\documentclass[12pt]{article}
\usepackage[hidelinks]{hyperref}
\usepackage[square,sort,comma,numbers]{natbib}
\usepackage{graphicx}
\usepackage{booktabs}
\title{Improving Speed and Interestingness of Graph-Based Specification Mining via Corpus Filtering}
\author{
    Andrew Mason\\
    \texttt{ajm188@case.edu}
    \and
    Jon Pfeil\\
    \texttt{jwp69@case.edu}
}
\date{December 8, 2014}
\begin{document}
\maketitle
\tableofcontents
\pagebreak

\section{Introduction}
Software verification, the ability to prove the correctness of a piece of software \cite{FormalSoftwareVerification}, is an appealing approach to improving software quality. However, the requirement of having formal descriptions of correctness has prevented the widespread use of software verification \cite{Ammons:2002:MS:503272.503275}. \textit{Specification Mining}, as described in \cite{Ammons:2002:MS:503272.503275}, is the machine learning approach to discovering formal specifications for a program interface or an abstract data type. A specification mining tool would reduce the major barrier to program verification by automating the generation of formal specifications.

Our project aims to push forward the current state of specification mining through the application of frequent subgraph mining algorithms to novel intermediate representations of programs.

\section{Background}
\subsection{Software Verification}
Knowing that a software system fulfills a set of requirements correctly is an
important concern in industry, especially for mission-critical software
systems, such as the avionics software in an airplane, or the software in
medical devices. Approaches to software verification can be separated into
categories, dynamic approaches and static approaches.
\\

\noindent Dynamic approaches to software verification include unit testing,
integration and system testing, and acceptance testing. While these methods 
can identify bugs in the software and help improve software quality, alone they
cannot confirm that the system is bug free and that the system fulfills all of
its requirements. A requirement may not be exercised by the tests, and there
may be a bug that occurs only on a particular input which the test suite does
not include.
\\

\noindent We prefer instead the static methods of software verification, known
also as program analysis or formal verification. These techniques aim to
provide a formal proof that a system satisfies a specified property. Numerous
approaches to formal verification exist, and we briefly highlight a few of
them below.
\\

\noindent Model-based certification aims to provide formal proofs that an
abstract model, such as a formal computational model, representing the software
system has a particular property\cite{FormalSoftwareVerification}. In this
approach, a verifier uses a model-checking tool to explore the state space of
the program, searching for error states, states where a certain property of the
system does not hold. One issue with this approach is that the state space for
even trivial programs can grow quite large, but predicate abstraction can be 
used to systematically reduce the state space\cite{FormalSoftwareVerification}.
\\

\noindent Deductive software proving, also referred to as program proving, aims
to express the correctness of a program as a set of mathematical statements,
which are then discharged using a theorem prover
\cite{DeductiveSoftwareVerification}. To do this, a formal specification
language must be defined and integrated with the desired programming language.
Filli√¢tre claims that the best method for achieving this is to tighten a
specification language to a programming language within a dedicated program
logic, which mixes programs and logical statements, infusing program
contstructs with logical ones in a single language
\cite{DeductiveSoftwareVerification}.

\subsection{Specification Mining}
Formal software verification has the potential to replace testing as the
standard method of verifying program correctness. However, formal program
verifiers are limited in that they can only check specified properties.
Additionally, authors Lo and Khoo claim that the difficulty in formulating a
set of formal properties has contributed to the lack of widespread adoption in
industry\cite{Lo_softwarespecification}. To solve this issue, the technique of
specification mining aims to discover non-trivial properties or specifications
in a software system to later be used by a program verifier.
\\

\noindent Several approaches to specification mining are described in the
literature, the first of which is a machine learning approach outlined by
Ammons et al. Their mining approach is based on program execution traces rather
than static analysis of source code. Ammons et al argue that this approach is
superior since the traces will only contain the feasible paths of execution.
Additionally, basing the mining on program traces ensure that only correct
execution paths are mined, thus preventing buggy paths from polluting the
results of the mining\cite{Ammons:2002:MS:503272.503275}. Their miner extracts
abstract scenarios from traces annotated with information about flow
dependence, which are small sets of independent interactions. These scenarios
are then fed into an automaton learner to learn the specifications. Ammons et
al give two reasons for this approach. First, the scenarios are much smaller
than the original traces, so the automaton learner learns the specifications
much faster. Second, the sizes of the scenarios are bounded, which they argue
make the specification mining tractable. The workflow of the miner looks like
\cite{Ammons:2002:MS:503272.503275}:\\
\includegraphics{machine_learning_miner_workflow.png}
\\

\noindent Lo and Khoo expand on the work of \cite{Ammons:2002:MS:503272.503275}
by describing their work in automaton-based specification mining, as well as
their work in mining Linear Temporal Logic (LTL) expressions and Live Sequence
Charts (LSC), which are alternate formalisms for representing specifications
\cite{Lo_softwarespecification}. Their approach also relies on execution traces
of the program. Lo and Khoo improve on \cite{Ammons:2002:MS:503272.503275} by
using a data mining approach that attempts to improve the quality of results,
since Ammons et al rely on the notion that traces give strong hints about
program rules, but do not really address the possibility that these traces may
contain errors. To this end, Lo and Khoo add an accuracy metric to measure the
performance of an automaton-based miner, which is measured by the notion of
recall and precision. They define recall and precision as ``the proportion of
sentences in $S_{inf}$ that is accepted by $S_{orig}$ and the proportion of
sentences in $S_{orig}$ that is accepted by $S_{inf}$ where $S_{orig}$ is the
original specification and $S_{inf}$ is the inferred specification
\cite{Lo_softwarespecification}.'' Next, the authors devise a framework they
call SMArTIC that splits the specification mining task into four pipelined
components. They claim that this improves the quality of the mining because it
identifies and filters out erroneous traces early in the mining, and ``the
over-generalization that occurs at the learning stage can be mitigated by
localization of the learning process to groups of related ... traces
\cite{Lo_softwarespecification}.''
\\

\noindent Lo and Khoo also discuss their work in LTL specification mining,
which is one of the most commonly-accepted formalisms by standard verifiers.
LTL expressions break automata-based specifications (which are global and
often complex) into smaller pieces which express what the authors call
strongly observed behavior or rules. To identify these rules, Lo and Khoo
introduce the notions of support, which is the number of traces exhibiting the
premise of the rule, and confidence, which is the likelihood of the premise of
the rule to be followed by its consequence\cite{Lo_softwarespecification}.
They employ a search space pruning strategy to mine these rules from the
execution traces.

\subsubsection{Limiting False Positives}
Le Goues and Weimer\cite{Goues:2009:SMF:1532891.1532925} claim that
specification inference techniques suffer from 90-99\% false positive rates,
and thus require a heavy burden of manual inspection, making these techniques
impractical for most software projects. By defining the notion of code
trustworthiness, they are able to achieve false positive rates of only 5\%.
Their approach statically estimates the trustworthiness of each code fragment
and then weights the contribution of each trace by its trustworthiness, which
is determined by the trustworthiness of the fragments visited in the trace, in
the actual specification mining\cite{Goues:2009:SMF:1532891.1532925}. The code
trustworthiness is based on the notion that some code is more likely to be
correct than others. Le Goues and Weimer estimate this likelihood by using the
results of many studies in software engineering. For example, studies have
shown that code that is modified more frequently is more likely to contain
defects, so the approach looks at information obtained from the version control
system to determine the rate of what the authors call code churn
\cite{Goues:2009:SMF:1532891.1532925}.

\subsection{Graphical Specification Mining}
\subsubsection{Program Dependence Graphs}
Several techinques have been described in the literature that perform
specification mining on an intermediate representation of the software known
as a procedure dependence graph (PDG). A PDG combines the information contained
in a data dependence graph and a control flow graph. For more information, see
\cite{Ferrante:1987:PDG:24039.24041}.

\subsubsection{Subgraph Isomorphism}
Finding repeated patterns in the PDGs is central to the ideas behind graphical
specification mining, and, therefore, so is the subgraph isomorphism problem.
The subgraph isomorphism problem asks the question: given graphs $G$ and $H$,
does there exist a subgraph $G_0$ of $G$ such that $G_0$ is isomorphic to $H$?
Such an isomorphism is illustrated in the following diagram (C highlights the 
subgraph of B that is isomorphic to A):
\begin{center}
\includegraphics{subgraph_isomorphism.png}
\end{center}

\subsubsection{Frequent Subgraph Mining}
Another fundamental technique in graphical specification mining is that of
frequent subgraph mining. Given a graph dataset
$D = \left\{ G_0, G_1, \ldots, G_n\right\}$, with $support(g)$ denoting the
number of graphs in $D$ in which $g$ is a subgraph, frequent subgraph mining
aims to find all subgraphs $g$ such that $support(g) \geq minSup$, where
$minSup$ is some minimum support, usually specified by a user
\cite{Yan:2002:GGS:844380.844811}. At the heart of frequent subgraph mining is
the subgraph isomorphism test.

\subsubsection{gSpan}
Yan and Han present an algorithm for mining frequent substructure
patterns, which they call gSpan. It is important to note that the authors
limit their discussion to frequent connected subgraphs only. gSpan explores
depth-first search (DFS) in frequent subgraph mining, introducing the concepts
of DFS lexicographical ordering and a minimum DFS code, which provide a
canonical labeling system to support DFS searching during the mining.
Definitions for these concepts can be found in
\cite{Yan:2002:GGS:844380.844811}. The subgraph mining subroutine of the
algorithm uses a recursive graph expansion strategy, growing the current
subgraph by one edge at a time to find the largest possible subgraph which is
still a frequent subgraph.

\subsubsection{CloseGraph}
Yan and Han expand upon their work on gSpan in their paper
``CloseGraph: Mining Closed Frequent Graph Patterns.'' They propose a new
algorithm which mines only closed frequent subgraph patterns, rather than all
of them. A graph $g$ is closed if there exists no proper super-graph with the
same support as $g$ \cite{Yan:2003:CMC:956750.956784}. This approach addresses
the issue in gSpan of the blowing up of frequent subgraphs. For example, an
$n$-edge graph has at most $2^n$ subgraphs, which contribute no new
information if they have the same support as the super-graph. Yan and Han
postulate that their approach, CloseGraph, both drastically reduces the number
of unnecessary graphs generated as well as significantly improves the
efficiency of the mining\cite{Yan:2003:CMC:956750.956784}. Their algorithm
makes use of some of the properties of gSpan, in particular DFS coding and
lexicographical ordering, and the restriction of graph extensions to right-most
extensions only, and defines the notion of equivalent occurence (see
\cite{Yan:2003:CMC:956750.956784}) to provide conditions for early
termination. Additionally, Yan and Han show that CloseGraph does not need to
store previously discovered graphs to prune newly discovered non-closed graphs
\cite{Yan:2003:CMC:956750.956784}. Finally, they show that CloseGraph can be
used with minimal effort to mine other structures, including many other types
of graphs (unlabeled, non-simple, directed, and disconnected) as well as trees.
\\

\section{Previous Work}
\subsection{Definitions}
\subsubsection{Graph Minors}
A graph $H$ is a minor of a graph $G$ if, by performing a series of edge and
vertex deletions and edge contractions on $G$, $H$ can be produced from $G$.

\subsubsection{Dependence Spheres}
In their paper, ``Discovering program rules and violations by mining
interprocedural dependencies,'' Chang and Podgurski give an approach for
constructing an interprocedural dependence sphere. The approach begins with
the call-site graph (CSG), $S$, of the function of interest, $f_b$. Then, $S$
is grown iteratively by adding nodes from PDGs of functions in the call tree
of $f_b$ if there exists a direct data dependency between the node and any
node in $S$. See \cite{DBLP:journals/smr/ChangP12} for more details.

\subsection{GMFMM}
\noindent Frequent subgraph mining is an important problem in the field of
specification mining, as these specifications can be modeled by graph minors
of PDGs. Hence, mining the PDG for graph minors results in the discovery of
program specifications. In \cite{DBLP:journals/smr/ChangP12}, Chang and
Podgurski give an approach, which they call greedy maximal frequent minor
mining (GMFMM), for mining maximal frequent minors from interprocedural
dependence spheres. By extending the scope of the minor to an interprocedural
level, two additional types of program specifications can be learned by this
approach: rules about the ordering of function calls, and rules regarding the
inputs and return values of functions. The authors define the notion of
maximal frequent subgraphs to be those which are not contained in any other
frequent subgraphs. Note that this notion is identical to the notion of a
closed graph defined in \cite{Yan:2003:CMC:956750.956784}. Rather than mining
all frequent subgraphs, the approach looks only for frequent minors, which
allows for certain variations in the structure of certain rules can be
encompassed by a single rule. Since Chang and Podgurski focus on the ordering
and conditional rules unique to interprocedural analysis, they offer a method
to reduce the intereprocedural dependence sphere to include only call-site
graph nodes and control point nodes. It is not difficult to extend the idea
behind this reduction to limit the scope of the dependence sphere to any
subset of node types that are of interest to the user in order to improve the
efficiency of the mining algorithm.

\section{Tools}
\label{section:Tools and Data Sources}
\subsection{Soot}
Soot is a Java optimization framework, intended to be used as either a stand-alone tool to inspect class files, or to develop optimizations or transformations on Java byte code. Soot provides several different intermediate representations of Java byte code: 

\begin{itemize}
    \item\textbf{Baf}: a streamlined representation of bytecode which is simple to manipulate.
    \item\textbf{Jimple}: a typed 3-address intermediate representation suitable for optimization. This is the primary representation used by Soot.
    \item\textbf{Shimple}: an SSA variation of Jimple.
    \item\textbf{Grimp}: an aggregated version of Jimple suitable for decompilation and code inspection.
    \item\textbf{Dava}: an abstract syntax tree-based representation. Produced via decompilation of the Jimple representation.
\end{itemize}
The Soot framework is often used for its support for implementing intraprocedural data-flow analyses. Soot also provides call graph information for interprocedural analysis as part of its output. 

\subsection{JPDG}
\label{subsection:JPDG}
JPDG is a tool developed by Tim Henderson which utilizes the Soot framework to generate procedure dependence graphs (PDGs) for Java programs. The PDGs can then be mined for frequent subgraphs to infer programming rules from source code.

\subsection{Parsemis}
% From: https://www2.cs.fau.de/EN/research/zold/ParSeMiS/index.html
ParSeMiS is the parallel and sequential mining suite from the Friedrich-Alexander Universit{\"a}t Erlangen-N{\"u}remburg. It utilizes parallel or specialized algorithms or heuristics to search for frequent, interesting substructures in graph datasets.

\subsection{Python Graph Tools}
graph-tool is a Python module for manipulation and statistical analysis of
graphs. Many of its data structures and algorithms are implemented in C++,
making it comparable in performance to a pure C/C++ graph library. The module
contains a wide array of features, most notably a function to find subgraph
isomorphisms.

\section{Data Source}
Due to the large computation time for even moderately sized projects, a test data set of small toy-programs was chosen. Ten sections of example programs were chosen from \url{http://www.tutorialspoint.com/javaexamples/}, a website that hosts example java code showing how to use standard library features. See Table \ref{program_list} for a list of sections used a a project corpus.

\begin{table}[ht]
\centerline{
    \begin{tabular}{@{}ll@{}}
    \toprule
       & Topic           \\ \midrule
    1  & Arrays          \\
    2  & Collections     \\
    3  & Data Structures \\
    4  & Date Time       \\
    5  & Directories     \\
    6  & Files           \\
    7  & Methods         \\
    8  & Networking      \\
    9  & Strings         \\
    10 & Threading       \\ \bottomrule
    \end{tabular}
}
\caption{\label{program_list}
    List of sections used as project corpus
}
\end{table}

For each topic, there are 8-15 examples. For use in this project, this set of files is the ``program'' or ``project'' (e.g. the Array program is a collection of 10 examples showing how to use java arrays). The hope was that programs exercising the standard library would be small enough to be computationally feasible for this project, while still having some number of non-trivial patterns.

\section{Methodology and Evaluation}
The following is an outline of the methodology we will use:

\begin{figure}[ht]
\centerline{
\includegraphics[width=\linewidth]{spec_mining_methodology.png}
}
\caption{\label{mining_methodology}
    Flowchart of methodology used
}
\end{figure}

\begin{enumerate}
    \item Obtain a corpus of java programs
    \item For each java program:
    \begin{enumerate}
        \item Generate the program's PDG via jpdg
        \item Run gSpan on the PDG to discover all patterns at a given support
        \item Record the patterns and run time of gSpan
    \end{enumerate}
    \item Create a pattern corpus by taking the union of each program's patterns
    \item For each pattern in pattern corpus:
    \begin{enumerate}
        \item Record the percentage of programs for which this was a frequent pattern
    \end{enumerate}
    \item For each java program:
    \begin{enumerate}
        \item Generate the program's PDG via jpdg
        \item For each pattern with a corpus percentage above some threshold, remove all subgraph isomorphisms from the PDG
        \item Run gSpan on the resulting PDG to discover all patterns at a given support
        \item Record the patterns and run time of gSpan
    \end{enumerate}
\end{enumerate}

\section{Results}
\subsection{Generating PDGs}
Running the programs through jpdg produces Program Dependency Graphs as dot files. Since these are at the bytecode level, the PDGS are extremely large even for small projects. Figure \ref{reader_pdg} and Figure \ref{server_pdg} are examples of two PDGs, each generated from one file inside their respective projects. They are just shown to give a sense of scale, since they are too large for the text to be readable.

\begin{figure}[ht]
\centerline{
\includegraphics[width=\linewidth]{patterns/reader_pdg_full.png}
}
\caption{\label{reader_pdg}
    PDG for Reader.java, a file in the File project
}
\end{figure}


\begin{figure}[ht]
\centerline{
\includegraphics[width=\linewidth]{patterns/full_network_small.png}
}
\caption{\label{server_pdg}
    PDG for Server.java, a file in the Networking project
}
\end{figure}

\subsection{Mining Non-trivial Patterns}
A ``Non-trivial'' pattern is one that represents an actual specification, rather than boilerplate java bytecode that will be included in most java projects. One of the examples used in previous specification mining literature is discovering the pattern of opening and closing sockets in network programming. We therefore expect that gSpan should be able to identify a pattern such as this in the Network project. Observing the patterns found in the Network program, we see that this is the case.

\begin{figure}[ht]
\centerline{
\includegraphics[width=\linewidth]{patterns/networking_pattern.png}
}
\caption{\label{socket_pattern}
    Frequent graph found in the Network project representing the socket open/close pattern
}
\end{figure}

Revisiting the PDG for Server.java, we can mark the pattern by doing a subgraph isomorphism search.

\begin{figure}[ht]
\centerline{
\includegraphics[width=\linewidth]{patterns/networking_isomorphism_full.png}
}
\caption{\label{networking_isomorphism}
    Highlighting socket pattern in Server.java PDG (labels omitted)
}
\end{figure}

\begin{figure}[ht]
\centerline{
\includegraphics[width=\linewidth]{patterns/networking_isomorphism_zoomed.png}
}
\caption{\label{networking_isomorphism_zoomed}
    Zooming in on highlighted socket pattern in Server.java PDG (labels omitted)
}
\end{figure}


\subsection{Mining Trivial Patterns}
There are many patterns that occur across a large percentage of our program corpus. These patterns are ``trivial'' in that they don't represent a program specification; rather, they represent common boilerplate java bytecode.

In our test corpus, there were two patterns that were frequent patterns in over 50\% of projects. Looking at these patterns, we can clearly see that they represent a getter and setter.

\begin{figure}[ht]
\centerline{
\includegraphics[width=7cm]{patterns/reader_getter.png}
}
\caption{\label{reader_getter}
    Getter pattern
}
\end{figure}

\begin{figure}[ht]
\centerline{
\includegraphics[width=7cm]{patterns/reader_setter.png}
}
\caption{\label{reader_setter}
    Setter pattern
}
\end{figure}

\subsection{Removing Trivial Patterns}
Revisiting the PDG for Reader.java, we can mark the getter and setter by doing a subgraph isomorphism search for each.

\begin{figure}[ht]
\centerline{
\includegraphics[width=\linewidth]{patterns/reader_getter_isomorphism.png}
}
\caption{\label{reader_getter_isomorphism}
    Highlighting getter pattern in Reader.java PDG (labels omitted)
}
\end{figure}

Given that we now know what getter/setter patterns look like in java bytecode, we can filter them out from our pattern sets to reduce the number of trivial patterns we return. In fact, since these should always appear as disconnected subgraphs (unlike the socket pattern), we can remove them from future PDGs {\em before} running gSpan, thereby reducing our input size and reducing the number of trivial patterns.

\subsection{Analysis}
\begin{table}[ht]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|l|l|}
\hline
\textbf{Project Name}    & \textbf{\begin{tabular}[c]{@{}l@{}}Num Patterns\\ (at \%5)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Time to Generate\\ (hh:mm:ss)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Num Patterns\\ after Filter\\  (at 50\%)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Time for Reduced\\  (hh:mm:ss)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Time Ratio \\ (Reduced/Initial)\end{tabular}} \\ \hline
\textbf{Arrays}          & 34                                                                       & 0:40:24                                                                        & 30                                                                                        & 0:39:01                                                                         & 0.9657                                                                           \\ \hline
\textbf{Collections}     & 51                                                                       & 1:11:45                                                                        & 46                                                                                        & 1:10:06                                                                         & 0.9771                                                                           \\ \hline
\textbf{Data Structures} & 20                                                                       & 0:34:10                                                                        & 18                                                                                        & 0:39:11                                                                         & 1.1466                                                                           \\ \hline
\textbf{DateTime}        & 14                                                                       & 0:18:36                                                                        & 12                                                                                        & 0:20:47                                                                         & 1.116                                                                            \\ \hline
\textbf{Directories}     & 8                                                                        & 0:11:31                                                                        & 8                                                                                         & 0:07:19                                                                         & 0.6353                                                                           \\ \hline
\textbf{Files}           & 26                                                                       & 0:31:09                                                                        & 22                                                                                        & 0:32:58                                                                         & 1.0582                                                                           \\ \hline
\textbf{Methods}         & 17                                                                       & 0:24:51                                                                        & 17                                                                                        & 0:19:56                                                                         & 0.8020                                                                           \\ \hline
\textbf{Networking}      & 37                                                                       & 0:41:22                                                                        & 34                                                                                        & 0:41:35                                                                         & 1.0051                                                                           \\ \hline
\textbf{Strings}         & 18                                                                       & 0:26:17                                                                        & 17                                                                                        & 0:20:53                                                                         & 0.7943                                                                           \\ \hline
\textbf{Threading}       & 43                                                                       & 1:06:26                                                                        & 37                                                                                        & 1:03:39                                                                         & 0.9579                                                                           \\ \hline
\end{tabular}
}
\caption{\label{result_table}
    Summary of pattern and run time results
}
\end{table}

\section{Conclusion}
pass

\pagebreak
\bibliographystyle{acm}
\bibliography{lit_survey}
\end{document}
